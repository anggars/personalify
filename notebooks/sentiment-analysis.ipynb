{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff681700",
   "metadata": {},
   "source": [
    "# Tugas Besar NLP: Analisis Sentimen Lirik Lagu (Genius & Personalify)\n",
    "\n",
    "**Analisis Emosi Lirik Lagu Berbasis Web Menggunakan Integrasi Genius API dan Model Transformer.**\n",
    "\n",
    "## 1. Pendahuluan\n",
    "Notebook ini bertujuan untuk mendemonstrasikan proses eksperimen NLP yang melandasi aplikasi **Personalify**. Proses mencakup:\n",
    "1.  **Data Collection:** Pengambilan data lirik secara *real-time* dari Genius API (menggunakan modul backend Personalify).\n",
    "2.  **Preprocessing:** Pembersihan teks lirik dari tag metadata.\n",
    "3.  **Model Comparison:** Membandingkan performa model Klasik (VADER) dengan model Deep Learning (RoBERTa Transformer).\n",
    "4.  **Evaluation:** Visualisasi perbandingan hasil deteksi emosi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27da07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# Setup Tampilan\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Load Token\n",
    "load_dotenv(\"../.env\")\n",
    "GENIUS_TOKEN = os.getenv(\"GENIUS_ACCESS_TOKEN\")\n",
    "\n",
    "if not GENIUS_TOKEN:\n",
    "    print(\"âš ï¸ WARNING: Token Genius tidak ditemukan.\")\n",
    "else:\n",
    "    print(\"âœ… SUCCESS: API Token loaded.\")\n",
    "\n",
    "# Import Module Backend\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'backend')))\n",
    "try:\n",
    "    # Kita tetap pakai search_artist_id dan get_lyrics_by_id dari backend\n",
    "    from app.genius_lyrics import get_lyrics_by_id, search_artist_id\n",
    "    print(\"âœ… SUCCESS: Modul Backend Personalify berhasil diimpor.\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ERROR: Gagal import modul backend. {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501db79e",
   "metadata": {},
   "source": [
    "## 2. Data Collection (Real-time Construction)\n",
    "\n",
    "Alih-alih menggunakan dataset statis, kita membangun dataset secara dinamis menggunakan **Genius API**.\n",
    "\n",
    "**Strategi Scraping:**\n",
    "1.  **Target:** Artis Campuran (Internasional & Lokal) untuk variasi bahasa dan genre.\n",
    "2.  **Filter:** Mengambil lagu berdasarkan **Popularitas (Pageviews)**, bukan tanggal rilis, agar data yang didapat adalah lagu-lagu *hits* yang liriknya valid.\n",
    "3.  **Handling Artis Lokal:** Menggunakan ID manual untuk artis lokal yang sering salah deteksi oleh API (misal: The Adams, Sore, Isyana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ecee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DAFTAR ARTIS LENGKAP (Pop + Indie + Metal + Emo + Lokal) ---\n",
    "# Strategi: Mencampur mainstream dengan genre ekstrem untuk variasi emosi maksimal.\n",
    "\n",
    "target_artists_input = [\n",
    "    # === 1. INTERNATIONAL HITS (Pop, R&B, HipHop) - Data Awal ===\n",
    "    {\"name\": \"The Beatles\", \"id\": 45},\n",
    "    {\"name\": \"Taylor Swift\", \"id\": 1421},\n",
    "    {\"name\": \"Drake\", \"id\": 130},\n",
    "    {\"name\": \"Eminem\", \"id\": 45},\n",
    "    {\"name\": \"The Weeknd\", \"id\": 536},\n",
    "    {\"name\": \"Coldplay\", \"id\": 626},\n",
    "    {\"name\": \"Bruno Mars\", \"id\": 102},\n",
    "    {\"name\": \"Ed Sheeran\", \"id\": 12418},\n",
    "    {\"name\": \"Justin Bieber\", \"id\": 357},\n",
    "    {\"name\": \"Ariana Grande\", \"id\": 6436},\n",
    "    {\"name\": \"Post Malone\", \"id\": 16098},\n",
    "    {\"name\": \"Travis Scott\", \"id\": 20260},\n",
    "    {\"name\": \"Mac Miller\", \"id\": 2300},\n",
    "    {\"name\": \"Frank Ocean\", \"id\": 2235},\n",
    "    {\"name\": \"Laufey\", \"id\": 1239683},\n",
    "    {\"name\": \"Dua Lipa\", \"id\": 12246},\n",
    "    {\"name\": \"Rich Brian\", \"id\": 303},\n",
    "    {\"name\": \"NIKI\", \"id\": 309},\n",
    "\n",
    "    # === 2. EMOTION BOOSTERS (Metal, Emo, Punk, Shoegaze) - Tambahan Baru ===\n",
    "    # Penyeimbang agar tidak terlalu banyak \"Neutral\"\n",
    "    {\"name\": \"Slipknot\", \"id\": 1459},          # Anger/Aggression\n",
    "    {\"name\": \"System of a Down\", \"id\": 436},    # Anger/Political\n",
    "    {\"name\": \"Bring Me The Horizon\", \"id\": 348},# Angst/Despair\n",
    "    {\"name\": \"Avenged Sevenfold\", \"id\": 230},   # Grief/Power\n",
    "    {\"name\": \"Metallica\", \"id\": 334},           # Anger\n",
    "    {\"name\": \"Rage Against the Machine\", \"id\": 667}, # Anger\n",
    "    {\"name\": \"Deftones\", \"id\": 1696},           # Desire/Shoegaze\n",
    "    {\"name\": \"My Chemical Romance\", \"id\": 444}, # Emo/Drama\n",
    "    {\"name\": \"American Football\", \"id\": 1427},  # Midwest Emo (Sad)\n",
    "    {\"name\": \"Modern Baseball\", \"id\": 18464},   # Emo (Sad/Nostalgia)\n",
    "    {\"name\": \"The Smiths\", \"id\": 976},          # Melancholy\n",
    "    {\"name\": \"Slowdive\", \"id\": 2862},           # Shoegaze (Dreamy)\n",
    "    {\"name\": \"Mitski\", \"id\": 296963},           # Sadness/Loneliness\n",
    "    {\"name\": \"Joji\", \"id\": 843},                # Sadboi R&B\n",
    "    {\"name\": \"XXXTENTACION\", \"id\": 12656},      # Depression/Anger\n",
    "    {\"name\": \"Lana Del Rey\", \"id\": 2182},       # Glamorous Sadness\n",
    "    {\"name\": \"Cigarettes After Sex\", \"id\": 349776}, # Romance/Desire\n",
    "    {\"name\": \"Blink-182\", \"id\": 87},            # Fun/Excitement\n",
    "    {\"name\": \"Green Day\", \"id\": 92},            # Punk/Rebellion\n",
    "    {\"name\": \"Paramore\", \"id\": 353},            # Angst/Energy\n",
    "    {\"name\": \"Radiohead\", \"id\": 604},           # Existential Dread\n",
    "    {\"name\": \"Arctic Monkeys\", \"id\": 1001},     # Cool/Indie\n",
    "    {\"name\": \"The Strokes\", \"id\": 257},         # Indie Rock\n",
    "    {\"name\": \"Pink Floyd\", \"id\": 563},          # Psychedelic/Deep\n",
    "    {\"name\": \"Muse\", \"id\": 637},                # Grandiose\n",
    "\n",
    "    # === 3. INDONESIAN HEROES (Indie, Pop, Rock, Math) - Data Awal ===\n",
    "    {\"name\": \"The Adams\", \"id\": 361962},\n",
    "    {\"name\": \"Sore\", \"id\": 361955},\n",
    "    {\"name\": \"Mocca\", \"id\": 140026},\n",
    "    {\"name\": \"Isyana Sarasvati\", \"id\": 654632},\n",
    "    {\"name\": \"Sheila On 7\", \"id\": 343924},\n",
    "    {\"name\": \"Dewa 19\", \"id\": 279875},\n",
    "    {\"name\": \"Tulus\", \"id\": 194472},\n",
    "    {\"name\": \"Raisa\", \"id\": 373902},\n",
    "    {\"name\": \"Payung Teduh\", \"id\": 370950},\n",
    "    {\"name\": \"Fourtwnty\", \"id\": 1185761},\n",
    "    {\"name\": \"Barasuara\", \"id\": 1068542},\n",
    "    {\"name\": \"Efek Rumah Kaca\", \"id\": 1031300},\n",
    "    {\"name\": \"Danilla\", \"id\": 1250672},\n",
    "    {\"name\": \"Sal Priadi\", \"id\": 1682206},\n",
    "    {\"name\": \"Bernadya\", \"id\": 3703366},       # Galau Brutal\n",
    "    \n",
    "    # ID Auto Search (Yang Aman)\n",
    "    {\"name\": \"eleventwelfth\", \"id\": None},\n",
    "    {\"name\": \"Murphy Radio\", \"id\": None},      # Math Rock\n",
    "    {\"name\": \"Reality Club\", \"id\": None},\n",
    "    {\"name\": \"Hindia\", \"id\": None},\n",
    "    {\"name\": \"Feast\", \"id\": None},\n",
    "    {\"name\": \"Pamungkas\", \"id\": None},\n",
    "    {\"name\": \"Nadin Amizah\", \"id\": None},\n",
    "    {\"name\": \"Kunto Aji\", \"id\": None},\n",
    "    {\"name\": \"Peterpan\", \"id\": None},\n",
    "    {\"name\": \"Yura Yunita\", \"id\": None},\n",
    "    {\"name\": \"Banda Neira\", \"id\": None},\n",
    "    {\"name\": \"White Shoes & The Couples Company\", \"id\": None},\n",
    "    {\"name\": \"Girl and Her Bad Mood\", \"id\": None},\n",
    "    \n",
    "    # Tambahan Keras Lokal (Biar makin variatif)\n",
    "    {\"name\": \"Burgerkill\", \"id\": None},        # Metal\n",
    "    {\"name\": \"Seringai\", \"id\": None},          # Rock\n",
    "    {\"name\": \"Amigdala\", \"id\": None}           # Folk Sedih\n",
    "]\n",
    "\n",
    "final_artists = []\n",
    "\n",
    "print(\"--- ðŸ” TAHAP 1: RESOLVE ARTIST IDs ---\")\n",
    "for artist in target_artists_input:\n",
    "    if artist['id'] is None:\n",
    "        print(f\"Mencari ID untuk: {artist['name']}...\")\n",
    "        try:\n",
    "            results = search_artist_id(artist['name'])\n",
    "            if results:\n",
    "                top = results[0]\n",
    "                print(f\"   âœ… Ditemukan: {top['name']} (ID: {top['id']})\")\n",
    "                final_artists.append({\"name\": top['name'], \"id\": top['id']})\n",
    "            else:\n",
    "                print(f\"   âŒ Gagal menemukan {artist['name']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ Error API: {e}\")\n",
    "    else:\n",
    "        final_artists.append(artist)\n",
    "\n",
    "# --- FUNGSI CUSTOM: AMBIL LAGU TERPOPULER SAJA ---\n",
    "def get_top_songs_manual(artist_id, limit=10):\n",
    "    url = f\"https://api.genius.com/artists/{artist_id}/songs\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv('GENIUS_ACCESS_TOKEN')}\"}\n",
    "    params = {\"sort\": \"popularity\", \"per_page\": limit}\n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=headers)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()['response']['songs']\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# 2. Mulai Scraping\n",
    "dataset = []\n",
    "SONGS_LIMIT = 10 \n",
    "\n",
    "print(f\"\\n--- ðŸš€ TAHAP 2: SCRAPING LAGU DARI {len(final_artists)} ARTIS ---\")\n",
    "\n",
    "for i, artist in enumerate(final_artists):\n",
    "    print(f\"[{i+1}/{len(final_artists)}] Memproses: {artist['name']}...\")\n",
    "    \n",
    "    songs = get_top_songs_manual(artist['id'], limit=SONGS_LIMIT)\n",
    "    \n",
    "    for song in songs:\n",
    "        lyrics_data = get_lyrics_by_id(song['id'])\n",
    "        \n",
    "        if lyrics_data:\n",
    "            dataset.append({\n",
    "                \"artist\": artist['name'],\n",
    "                \"title\": song['title'],\n",
    "                \"lyrics\": lyrics_data['lyrics']\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "print(f\"\\nâœ… Selesai! Total Dataset: {len(df)} lagu.\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b5fd22",
   "metadata": {},
   "source": [
    "## 3. Preprocessing & Translation\n",
    "\n",
    "Karena model NLP yang digunakan (VADER & RoBERTa) dilatih menggunakan Bahasa Inggris, lirik berbahasa Indonesia (seperti dari Tulus atau Dewa 19) harus diterjemahkan terlebih dahulu.\n",
    "\n",
    "**Tahapan:**\n",
    "1.  **Auto-Translation:** Menggunakan `deep-translator` untuk mendeteksi dan menerjemahkan lirik non-Inggris.\n",
    "2.  **Cleaning:** Menghapus metadata Genius seperti `[Verse]`, `[Chorus]` dan tanda baca.\n",
    "3.  **Feature Extraction:** Menghitung TF-IDF sebagai representasi numerik untuk visualisasi clustering nanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1908e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# 1. Fungsi Cleaning\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'\\[.*?\\]', '', text) # Hapus tag [Chorus]\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Hapus tanda baca\n",
    "    text = re.sub(r'\\n+', ' ', text)    # Hapus enter\n",
    "    return text.strip().lower()\n",
    "\n",
    "# 2. Fungsi Translate (AUTO DETECT)\n",
    "def translate_if_needed(text):\n",
    "    try:\n",
    "        if not text: return \"\"\n",
    "        # Batasi karakter biar ga error Google Translate\n",
    "        text_chunk = text[:4500] \n",
    "        translator = GoogleTranslator(source='auto', target='en')\n",
    "        translated = translator.translate(text_chunk)\n",
    "        return translated\n",
    "    except Exception as e:\n",
    "        return text \n",
    "\n",
    "print(\"ðŸŒ Sedang menerjemahkan lirik (ini memakan waktu)...\")\n",
    "\n",
    "# A. Translate\n",
    "df['translated_lyrics'] = df['lyrics'].apply(translate_if_needed)\n",
    "\n",
    "# B. Cleaning\n",
    "df['cleaned_lyrics'] = df['translated_lyrics'].apply(clean_text)\n",
    "\n",
    "print(\"âœ… Terjemahan & Cleaning Selesai!\")\n",
    "\n",
    "# --- [PENTING] SAVE KE CSV SEBAGAI BUKTI ---\n",
    "# File ini yang nanti kamu kumpulin atau tunjukin ke dosen \"Ini dataset saya Pak\"\n",
    "df.to_csv(\"genius-lyrics-dataset.csv\", index=False)\n",
    "print(\"ðŸ’¾ Dataset berhasil diexport ke 'genius-lyrics-dataset.csv'\")\n",
    "\n",
    "# 3. Feature Extraction (TF-IDF)\n",
    "print(\"ðŸ§® Menghitung Vektorisasi Teks...\")\n",
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "tfidf_matrix = tfidf.fit_transform(df['cleaned_lyrics']).toarray()\n",
    "df['tfidf_vector'] = list(tfidf_matrix)\n",
    "\n",
    "df[['artist', 'title', 'cleaned_lyrics']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e444c8",
   "metadata": {},
   "source": [
    "## 4. Model Comparison (Inference)\n",
    "\n",
    "Kita membandingkan dua pendekatan berbeda:\n",
    "\n",
    "1.  **VADER (Baseline):** Model berbasis aturan (*lexicon*) yang menghitung skor sentimen berdasarkan kamus kata. Output: Positif/Negatif/Netral.\n",
    "2.  **RoBERTa (Advanced):** Model *Transformer* yang sudah dilatih (Pre-trained) pada dataset GoEmotions. Output: 28 Emosi spesifik.\n",
    "\n",
    "Untuk keperluan evaluasi, output 28 emosi RoBERTa akan dipetakan (*mapping*) kembali ke 3 sentimen dasar agar bisa dibandingkan *apple-to-apple* dengan VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a68a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODEL 1: VADER (Lexicon Based / Baseline) ---\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "def predict_vader(text):\n",
    "    score = vader.polarity_scores(text)\n",
    "    # Threshold VADER: > 0.05 Positif, < -0.05 Negatif\n",
    "    if score['compound'] >= 0.05: return \"Positive\"\n",
    "    elif score['compound'] <= -0.05: return \"Negative\"\n",
    "    else: return \"Neutral\"\n",
    "\n",
    "df['vader_pred'] = df['cleaned_lyrics'].apply(predict_vader)\n",
    "\n",
    "# --- MODEL 2: RoBERTa (Transformer / Advanced) ---\n",
    "from transformers import pipeline\n",
    "print(\"ðŸ¤– Loading Model RoBERTa (GoEmotions)...\")\n",
    "classifier = pipeline(\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\")\n",
    "\n",
    "def predict_roberta(text):\n",
    "    try:\n",
    "        # Potong lirik jadi 512 token (limit BERT)\n",
    "        res = classifier(text[:512])[0] \n",
    "        return res['label']\n",
    "    except: return \"neutral\"\n",
    "\n",
    "print(\"ðŸ¤– Sedang klasifikasi emosi (agak lama)...\")\n",
    "df['roberta_emotion'] = df['cleaned_lyrics'].apply(predict_roberta)\n",
    "\n",
    "# Mapping Emosi RoBERTa ke 3 Sentimen (Supaya bisa dibandingin head-to-head)\n",
    "pos_list = ['admiration', 'amusement', 'approval', 'caring', 'desire', 'excitement', 'gratitude', 'joy', 'love', 'optimism', 'pride', 'relief']\n",
    "neg_list = ['anger', 'annoyance', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'fear', 'grief', 'nervousness', 'remorse', 'sadness']\n",
    "\n",
    "def map_sentiment(emo):\n",
    "    if emo in pos_list: return \"Positive\"\n",
    "    elif emo in neg_list: return \"Negative\"\n",
    "    else: return \"Neutral\"\n",
    "\n",
    "df['roberta_mapped'] = df['roberta_emotion'].apply(map_sentiment)\n",
    "print(\"âœ… Selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26c55f",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics\n",
    "\n",
    "Menggunakan RoBERTa sebagai *Ground Truth* (karena asumsi model Deep Learning lebih akurat), kita mengukur seberapa baik VADER dapat mengikuti prediksi RoBERTa.\n",
    "\n",
    "Metrik yang digunakan:\n",
    "* **Accuracy:** Ketepatan keseluruhan.\n",
    "* **F1-Score:** Keseimbangan antara Precision dan Recall.\n",
    "* **MCC (Matthews Correlation Coefficient):** Ukuran kualitas klasifikasi biner/multiclass yang valid meski data tidak seimbang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9910719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kita anggap RoBERTa sebagai \"Ground Truth\" (Label Benar)\n",
    "y_true = df['roberta_mapped']\n",
    "y_pred = df['vader_pred']\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# 1. Classification Report Lengkap\n",
    "print(\"=== ðŸ“Š CLASSIFICATION REPORT (VADER vs RoBERTa) ===\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=labels))\n",
    "\n",
    "# 2. Hitung Metrik Spesifik buat Tabel\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "# 3. Dataframe Perbandingan\n",
    "metrics_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'MCC (Matthews Correlation)', 'Threshold VADER'],\n",
    "    'Score': [acc, prec, rec, f1, mcc, \"Â±0.05\"]\n",
    "})\n",
    "\n",
    "print(\"\\n=== ðŸ“ˆ TABEL RINGKASAN METRIK ===\")\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9660b5a8",
   "metadata": {},
   "source": [
    "## 6. Dashboard Visualisasi\n",
    "\n",
    "Bagian ini menampilkan ringkasan visual dari hasil analisis:\n",
    "1.  **Confusion Matrix:** Melihat pola kesalahan prediksi VADER.\n",
    "2.  **Pie Chart:** Proporsi emosi dominan yang dideteksi sistem.\n",
    "3.  **Bar Chart:** Perbandingan distribusi sentimen antara kedua model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a081da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Confusion Matrix (Seberapa akurat VADER menebak RoBERTa?)\n",
    "plt.subplot(2, 2, 1)\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix\\n(Kesesuaian VADER thd RoBERTa)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Prediksi VADER')\n",
    "plt.ylabel('Label RoBERTa')\n",
    "\n",
    "# 2. Pie Chart (Distribusi Emosi Detail)\n",
    "plt.subplot(2, 2, 2)\n",
    "emo_counts = df['roberta_emotion'].value_counts().head(8)\n",
    "plt.pie(emo_counts, labels=emo_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))\n",
    "plt.title('Top 8 Emosi Terdeteksi (RoBERTa)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Bar Chart Perbandingan (Side-by-Side)\n",
    "plt.subplot(2, 2, 3)\n",
    "comp_df = pd.DataFrame({\n",
    "    'Model': ['VADER']*len(df) + ['RoBERTa']*len(df),\n",
    "    'Sentiment': list(df['vader_pred']) + list(df['roberta_mapped'])\n",
    "})\n",
    "sns.countplot(data=comp_df, x='Sentiment', hue='Model', palette='viridis', order=labels)\n",
    "plt.title('Perbandingan Distribusi Sentimen', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Tabel Sampel Data (Biar keliatan judul lagunya)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.axis('off')\n",
    "sample_data = df[['artist', 'title', 'roberta_emotion']].sample(10).values\n",
    "plt.table(cellText=sample_data, colLabels=['Artist', 'Title', 'Emotion'], loc='center', cellLoc='left', colColours=['#eeeeee']*3)\n",
    "plt.title('Sampel Hasil Analisis Lagu', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4431d30",
   "metadata": {},
   "source": [
    "## 7. Lyrical Clustering (PCA Projection)\n",
    "\n",
    "Menggunakan teknik **Principal Component Analysis (PCA)** untuk mereduksi dimensi vektor TF-IDF menjadi 2 dimensi.\n",
    "\n",
    "Titik-titik yang berdekatan dalam grafik ini menunjukkan lagu-lagu yang memiliki kemiripan penggunaan kata (*lexical similarity*), diwarnai berdasarkan sentimen emosi mereka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA (Principal Component Analysis) untuk mereduksi dimensi TF-IDF jadi 2D (x, y)\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(tfidf_matrix)\n",
    "\n",
    "df['x'] = coords[:, 0]\n",
    "df['y'] = coords[:, 1]\n",
    "\n",
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "# Plot Titik-Titik\n",
    "sns.scatterplot(\n",
    "    data=df, x='x', y='y', \n",
    "    hue='roberta_mapped',  # Warna berdasarkan sentimen\n",
    "    style='artist',        # Bentuk titik berdasarkan artis\n",
    "    s=200, alpha=0.8, palette='deep'\n",
    ")\n",
    "\n",
    "# Label Judul Lagu (Untuk beberapa titik saja biar gak numpuk)\n",
    "for i in range(0, len(df), 2): \n",
    "    plt.text(df.x[i]+0.01, df.y[i], df.title[i], fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.title('Lyrical Clustering Visualization (PCA)\\nLagu yang berdekatan memiliki kemiripan kata-kata', fontsize=15)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad01beb",
   "metadata": {},
   "source": [
    "## 8. Kesimpulan\n",
    "\n",
    "Berdasarkan hasil eksperimen di atas:\n",
    "\n",
    "1.  **Keterbatasan Baseline:** Model VADER cenderung menggeneralisasi lirik lagu menjadi \"Positive\" atau \"Negative\". Hal ini kurang relevan untuk aplikasi musik, karena lagu sedih (*sadness*) atau lagu galau (*remorse*) seringkali dikategorikan salah sebagai \"Negative\" atau bahkan \"Positive\" jika menggunakan kata-kata puitis.\n",
    "    \n",
    "2.  **Keunggulan Transformer:** Model RoBERTa mampu menangkap nuansa emosi yang jauh lebih kaya (*fine-grained emotion*). Seperti terlihat pada grafik, model ini bisa membedakan antara *admiration*, *love*, *sadness*, hingga *excitement*.\n",
    "\n",
    "**Keputusan Deployment:**\n",
    "Oleh karena itu, aplikasi **Personalify** menggunakan model **Transformer (RoBERTa)** di sisi *backend* (FastAPI) untuk memberikan pengalaman pengguna yang lebih akurat dalam mendeteksi *vibe* lagu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
